{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "38863182",
      "metadata": {},
      "source": [
        "#LLM from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35fEiZCgin1b",
      "metadata": {
        "id": "35fEiZCgin1b"
      },
      "source": [
        "importing all our dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "tZBq_KJ7isHT",
      "metadata": {
        "id": "tZBq_KJ7isHT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pprint\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ENsxoLcznMK4",
      "metadata": {
        "id": "ENsxoLcznMK4"
      },
      "source": [
        "training dataset with just a few hard-coded input and output text sequences and then programmatically build a vocabulary using all words in those text sequences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "RFyez3Lpitks",
      "metadata": {
        "id": "RFyez3Lpitks"
      },
      "outputs": [],
      "source": [
        "def get_data_and_vocab():\n",
        "    # Define training data\n",
        "    training_data = {\n",
        "        \"how are you\": \"i am fine <end>\",\n",
        "        \"tell me about yourself\": \"i love travelling, coding<end>\",\n",
        "        \"what is your name\": \"Adam <end>\",\n",
        "        \"who is nice\": \"Adam <end>\",\n",
        "        \"where is Adam\": \"at home <end>\",\n",
        "        \"how is Adam\": \"i dont know <end>\",\n",
        "        \"who are you\": \"your companion <end>\"\n",
        "    }\n",
        "\n",
        "    # Extract input and target phrases\n",
        "    data_words = [k for k, _ in training_data.items()]\n",
        "    target_words = [v for _, v in training_data.items()]\n",
        "\n",
        "    vocabulary_words = list(set([element.lower() for nestedlist in [x.split(\" \") for x in data_words] for element in nestedlist] + [element.lower() for nestedlist in [x.split(\" \") for x in target_words] for element in nestedlist]))\n",
        "    vocabulary_words.remove(\"<end>\")\n",
        "    vocabulary_words.append(\"<end>\")\n",
        "    vocabulary_words.insert(0, \"\")\n",
        "\n",
        "    # Create mappings from word to index and index to word\n",
        "    word_to_ix = {vocabulary_words[k].lower(): k for k in range(len(vocabulary_words))}\n",
        "    ix_to_word = {v: k for k, v in word_to_ix.items()}\n",
        "\n",
        "    return training_data, data_words, target_words, vocabulary_words, word_to_ix, ix_to_word\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "nZyjbEyBmODX",
      "metadata": {
        "id": "nZyjbEyBmODX"
      },
      "outputs": [],
      "source": [
        "training_data, data_words, target_words, vocabulary_words, word_to_ix, ix_to_word = get_data_and_vocab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "SR95aSpHmSlc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR95aSpHmSlc",
        "outputId": "7d229031-bd89-4ac7-c8dc-70f2feba8c38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'how are you': 'i am fine <end>',\n",
              " 'tell me about yourself': 'i love travelling, coding<end>',\n",
              " 'what is your name': 'Adam <end>',\n",
              " 'who is nice': 'Adam <end>',\n",
              " 'where is Adam': 'at home <end>',\n",
              " 'how is Adam': 'i dont know <end>',\n",
              " 'who are you': 'your companion <end>'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3_BBvVXcmTtl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_BBvVXcmTtl",
        "outputId": "83582823-fae0-4d50-adc2-34de63c3f92b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['how are you',\n",
              " 'tell me about yourself',\n",
              " 'what is your name',\n",
              " 'who is nice',\n",
              " 'where is Adam',\n",
              " 'how is Adam',\n",
              " 'who are you']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_words"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pe5x5200oA2s",
      "metadata": {
        "id": "pe5x5200oA2s"
      },
      "source": [
        "defining two helper functions to convert text sequences into its corresponding tensors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "IpuWH0EojGBG",
      "metadata": {
        "id": "IpuWH0EojGBG"
      },
      "outputs": [],
      "source": [
        "# Function to convert a batch of sequences of words to a tensor of indices\n",
        "def words_to_tensor(seq_batch, device=None):\n",
        "    index_batch = []\n",
        "\n",
        "    for seq in seq_batch:\n",
        "        word_list = seq.lower().split(\" \")\n",
        "        indices = [word_to_ix[word] for word in word_list if word in word_to_ix]\n",
        "        t = torch.tensor(indices)\n",
        "        if device is not None:\n",
        "            t = t.to(device)\n",
        "        index_batch.append(t)\n",
        "\n",
        "    return pad_tensors(index_batch)\n",
        "\n",
        "# Function to convert a tensor of indices to a list of sequences of words\n",
        "def tensor_to_words(tensor):\n",
        "    index_batch = tensor.cpu().numpy().tolist()\n",
        "    res = []\n",
        "    for indices in index_batch:\n",
        "        words = []\n",
        "        for ix in indices:\n",
        "            words.append(ix_to_word[ix].lower())\n",
        "            if ix == word_to_ix[\"<end>\"]:\n",
        "                break\n",
        "        res.append(\" \".join(words))\n",
        "    return res\n",
        "\n",
        "# Function to pad a list of tensors to the same length\n",
        "def pad_tensors(list_of_tensors):\n",
        "    tensor_count = len(list_of_tensors) if not torch.is_tensor(list_of_tensors) else list_of_tensors.shape[0]\n",
        "    max_dim = max(t.shape[0] for t in list_of_tensors)\n",
        "    res = []\n",
        "    for t in list_of_tensors:\n",
        "        res_t = torch.zeros(max_dim, *t.shape[1:]).type(t.dtype).to(t.device)\n",
        "        res_t[:t.shape[0]] = t\n",
        "        res.append(res_t)\n",
        "\n",
        "    # Concatenate tensors along a new dimension\n",
        "    res = torch.cat(res)\n",
        "    firstDim = len(list_of_tensors)\n",
        "    secondDim = max_dim\n",
        "\n",
        "    return res.reshape(firstDim, secondDim, *res.shape[1:])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ohwUwAY0ocAi",
      "metadata": {
        "id": "ohwUwAY0ocAi"
      },
      "source": [
        "defining architecture of the model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "zogsaB1boV-e",
      "metadata": {
        "id": "zogsaB1boV-e"
      },
      "outputs": [],
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_size, head_count):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.head_count = head_count\n",
        "\n",
        "        # Create linear layers for query, key and value projections for each head\n",
        "        self.query_layers = nn.ModuleList([nn.Linear(embed_size, embed_size, bias=False) for _ in range(head_count)])\n",
        "        self.key_layers = nn.ModuleList([nn.Linear(embed_size, embed_size, bias=False) for _ in range(head_count)])\n",
        "        self.value_layers = nn.ModuleList([nn.Linear(embed_size, embed_size, bias=False) for _ in range(head_count)])\n",
        "        self.fc_out = nn.Linear(head_count * embed_size, embed_size)\n",
        "\n",
        "    def forward(self, embeddings):\n",
        "        batch_size, token_count = embeddings.shape[:2]\n",
        "        qkvs = torch.zeros(self.head_count, 3, batch_size, token_count, self.embed_size).to(embeddings.device)\n",
        "\n",
        "        for i in range(self.head_count):\n",
        "            qkvs[i, 0] = self.query_layers[i](embeddings)\n",
        "            qkvs[i, 1] = self.key_layers[i](embeddings)\n",
        "            qkvs[i, 2] = self.value_layers[i](embeddings)\n",
        "\n",
        "        energy = torch.zeros(self.head_count, batch_size, token_count, token_count).to(embeddings.device)\n",
        "        mask = torch.triu(torch.ones((token_count, token_count)), diagonal=1).bool()\n",
        "\n",
        "        for h in range(self.head_count):\n",
        "            for b in range(batch_size):\n",
        "                for i in range(token_count):\n",
        "                    for j in range(token_count):\n",
        "                        energy[h, b, i, j] = torch.dot(qkvs[h, 0, b, i], qkvs[h, 1, b, j])\n",
        "                energy[h, b] = energy[h, b].masked_fill(mask, float('-inf'))\n",
        "\n",
        "        attention = torch.nn.functional.softmax(energy, dim=3)\n",
        "\n",
        "        out = torch.zeros(batch_size, token_count, self.head_count, self.embed_size).to(embeddings.device)\n",
        "        for h in range(self.head_count):\n",
        "            for b in range(batch_size):\n",
        "                for i in range(token_count):\n",
        "                    for j in range(token_count):\n",
        "                        out[b, i, h] += (attention[h, b, i, j] * qkvs[h, 2, b, j])\n",
        "\n",
        "        out = out.reshape(batch_size, token_count, self.head_count * self.embed_size)\n",
        "        return self.fc_out(out)\n",
        "\n",
        "    def masked_attention(self, energy):\n",
        "        max_token_count, embed_size, _ = energy.size()\n",
        "\n",
        "        mask = torch.triu(torch.ones((max_token_count, max_token_count)), diagonal=1) * float('-inf')\n",
        "        mask = mask.unsqueeze(0).unsqueeze(0)\n",
        "        mask = mask.expand(batch_size, embed_size, -1, -1)\n",
        "\n",
        "        masked_scores = energy + mask.to(energy.device)\n",
        "\n",
        "        return masked_scores.to(energy.device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wX02xCmmo-Pm",
      "metadata": {
        "id": "wX02xCmmo-Pm"
      },
      "source": [
        "Adding additional transformer layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "-IvTM8Jbo06e",
      "metadata": {
        "id": "-IvTM8Jbo06e"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_size, head_count):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attention = SelfAttention(embed_size, head_count)\n",
        "        self.norm1 = nn.LayerNorm(embed_size)\n",
        "        self.norm2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "        # Feed-forward neural network\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_size, embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embed_size, embed_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, embeddings):\n",
        "        attention = self.attention(embeddings)\n",
        "        out = self.norm1(attention + embeddings)\n",
        "        out = attention + self.feed_forward(out)\n",
        "        out = self.norm2(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bE3Eh8IkpG73",
      "metadata": {
        "id": "bE3Eh8IkpG73"
      },
      "source": [
        "Combining everything together\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6I3bdCmWpD8N",
      "metadata": {
        "id": "6I3bdCmWpD8N"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, num_layers, head_count):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.word_embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.layers = nn.ModuleList(\n",
        "            [TransformerBlock(embed_size, head_count) for _ in range(num_layers)]\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, input_tokens, mask=None):\n",
        "        batch_size, token_count = input_tokens.shape[:2]\n",
        "        out = self.word_embedding(input_tokens)\n",
        "        positions = torch.arange(0, token_count).expand(batch_size, token_count).to(input_tokens.device)\n",
        "        position_encoding = self.position_encoding(positions, self.embed_size)\n",
        "        out += position_encoding.reshape(out.shape)\n",
        "\n",
        "        # Pass through each transformer block\n",
        "        for layer in self.layers:\n",
        "            out = layer(out)\n",
        "        out = self.fc_out(out[:, -1, :].reshape(batch_size, self.embed_size)).reshape(batch_size, self.vocab_size)\n",
        "        return torch.nn.functional.softmax(out, dim=1)\n",
        "\n",
        "    def position_encoding(self, positions, embed_size):\n",
        "        angle_rads = self.get_angles(\n",
        "            positions.unsqueeze(2).float(),\n",
        "            torch.arange(embed_size)[None, None, :].float().to(positions.device),\n",
        "            embed_size\n",
        "        )\n",
        "        sines = torch.sin(angle_rads[:, :, 0::2])\n",
        "        cosines = torch.cos(angle_rads[:, :, 1::2])\n",
        "        pos_encoding = torch.cat([sines, cosines], dim=-1)\n",
        "        pos_encoding = pos_encoding[None, ...]\n",
        "        return pos_encoding\n",
        "\n",
        "    def get_angles(self, pos, i, embed_size):\n",
        "        angle_rates = 1 / torch.pow(10000, (2 * (i//2)) / embed_size)\n",
        "        return pos * angle_rates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PrLB3A16p6kI",
      "metadata": {
        "id": "PrLB3A16p6kI"
      },
      "source": [
        "defining function to make predictions using our model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "eQ50JUkepLIf",
      "metadata": {
        "id": "eQ50JUkepLIf"
      },
      "outputs": [],
      "source": [
        "def infer_recursive(model, input_vectors, max_output_token_count=10):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "\n",
        "    # Loop over sequences in the batch\n",
        "    for i in range(input_vectors.shape[0]):\n",
        "        print(f\"Infering sequence {i}\")\n",
        "        input_vector = input_vectors[i].reshape(1, input_vectors.shape[1])\n",
        "        predicted_sequence = []\n",
        "        wc = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            while True:\n",
        "                output = model(input_vector)\n",
        "                predicted_index = output[0, :].argmax().item()\n",
        "                predicted_sequence.append(predicted_index)\n",
        "                if predicted_index == word_to_ix['<end>'] or wc > max_output_token_count:\n",
        "                    break\n",
        "                input_vector = torch.cat([input_vector, torch.tensor([[predicted_index]])], dim=1)\n",
        "                wc += 1\n",
        "        outputs.append(torch.tensor(predicted_sequence))\n",
        "    outputs = pad_tensors(outputs)\n",
        "    return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RoZSv479qUOe",
      "metadata": {
        "id": "RoZSv479qUOe"
      },
      "source": [
        "defining training function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "dNPzXrCvqSG-",
      "metadata": {
        "id": "dNPzXrCvqSG-"
      },
      "outputs": [],
      "source": [
        "def train_recursive(model, data, targets, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    total_loss = 0\n",
        "    batch_size, token_count, token_count_out = data.shape[0], data.shape[1], targets.shape[1]\n",
        "\n",
        "    # Loop over sequences in the batch\n",
        "    for b in range(batch_size):\n",
        "        end_encountered = False\n",
        "        cur_count = 0\n",
        "        while not end_encountered:\n",
        "            target_vector = torch.zeros(model.vocab_size).to(data.device)\n",
        "\n",
        "            if cur_count != token_count_out:\n",
        "                expected_next_token_idx = targets[b, cur_count]\n",
        "                target_vector[expected_next_token_idx] = 1\n",
        "\n",
        "            if cur_count > 0:\n",
        "                model_input = data[b].reshape(token_count).to(data.device)\n",
        "                part_of_output = targets[b, :cur_count].to(data.device)\n",
        "                model_input = torch.cat((model_input, part_of_output))\n",
        "            else:\n",
        "                model_input = data[b]\n",
        "            out = model(model_input.reshape(1, token_count + cur_count))\n",
        "            loss = criterion(out, target_vector.reshape(out.shape))\n",
        "            total_loss += loss\n",
        "            cur_count += 1\n",
        "\n",
        "            if cur_count > token_count_out:\n",
        "                end_encountered = True\n",
        "\n",
        "    # Backpropagate gradients and update model parameters\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    return total_loss.item() / batch_size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wozOu5Zbqax7",
      "metadata": {
        "id": "wozOu5Zbqax7"
      },
      "source": [
        "combining training and inference functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "eGibPoITqYQ3",
      "metadata": {
        "id": "eGibPoITqYQ3"
      },
      "outputs": [],
      "source": [
        "# Function to demonstrate training and inference\n",
        "def example_training_and_inference():\n",
        "    vocab_size = len(word_to_ix)\n",
        "    embed_size = 512\n",
        "    num_layers = 4\n",
        "    heads = 3\n",
        "\n",
        "    device = torch.device(\"cpu\")\n",
        "    model = Transformer(vocab_size, embed_size, num_layers, heads).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    data = words_to_tensor(data_words, device=device)\n",
        "    targets = words_to_tensor(target_words, device=device)\n",
        "\n",
        "    for epoch in range(100):\n",
        "        avg_loss = train_recursive(model, data, targets, optimizer, criterion)\n",
        "        print(f'Epoch {epoch + 1}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "    input_vector = words_to_tensor(data_words, device=device)\n",
        "    predicted_vector = infer_recursive(model, input_vector)\n",
        "    predicted_words = tensor_to_words(predicted_vector)\n",
        "\n",
        "    # Print training data and model output\n",
        "    print(\"\\n\\n\\n\")\n",
        "    print(\"Training Data:\")\n",
        "    pprint.pprint(training_data)\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"Model Inference:\")\n",
        "    result_data = {data_words[k]: predicted_words[k] for k in range(len(predicted_words))}\n",
        "    pprint.pprint(result_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "LJ8uPSH5qeE-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ8uPSH5qeE-",
        "outputId": "a9e09d17-41dd-49a8-8152-d70abf9e0acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 13.3204\n",
            "Epoch 2, Loss: 13.2285\n",
            "Epoch 3, Loss: 13.0901\n",
            "Epoch 4, Loss: 12.9259\n",
            "Epoch 5, Loss: 12.7630\n",
            "Epoch 6, Loss: 12.6260\n",
            "Epoch 7, Loss: 12.5078\n",
            "Epoch 8, Loss: 12.4012\n",
            "Epoch 9, Loss: 12.2810\n",
            "Epoch 10, Loss: 12.1831\n",
            "Epoch 11, Loss: 12.1164\n",
            "Epoch 12, Loss: 12.0619\n",
            "Epoch 13, Loss: 12.0116\n",
            "Epoch 14, Loss: 11.9566\n",
            "Epoch 15, Loss: 11.8977\n",
            "Epoch 16, Loss: 11.8400\n",
            "Epoch 17, Loss: 11.7879\n",
            "Epoch 18, Loss: 11.7414\n",
            "Epoch 19, Loss: 11.6961\n",
            "Epoch 20, Loss: 11.6510\n",
            "Epoch 21, Loss: 11.6039\n",
            "Epoch 22, Loss: 11.5619\n",
            "Epoch 23, Loss: 11.5322\n",
            "Epoch 24, Loss: 11.5118\n",
            "Epoch 25, Loss: 11.4951\n",
            "Epoch 26, Loss: 11.4764\n",
            "Epoch 27, Loss: 11.4550\n",
            "Epoch 28, Loss: 11.4322\n",
            "Epoch 29, Loss: 11.4068\n",
            "Epoch 30, Loss: 11.3781\n",
            "Epoch 31, Loss: 11.3453\n",
            "Epoch 32, Loss: 11.3089\n",
            "Epoch 33, Loss: 11.2726\n",
            "Epoch 34, Loss: 11.2389\n",
            "Epoch 35, Loss: 11.2069\n",
            "Epoch 36, Loss: 11.1786\n",
            "Epoch 37, Loss: 11.1508\n",
            "Epoch 38, Loss: 11.1171\n",
            "Epoch 39, Loss: 11.0712\n",
            "Epoch 40, Loss: 11.0117\n",
            "Epoch 41, Loss: 10.9476\n",
            "Epoch 42, Loss: 10.8977\n",
            "Epoch 43, Loss: 10.8699\n",
            "Epoch 44, Loss: 10.8506\n",
            "Epoch 45, Loss: 10.8269\n",
            "Epoch 46, Loss: 10.7962\n",
            "Epoch 47, Loss: 10.7599\n",
            "Epoch 48, Loss: 10.7204\n",
            "Epoch 49, Loss: 10.6840\n",
            "Epoch 50, Loss: 10.6553\n",
            "Epoch 51, Loss: 10.6382\n",
            "Epoch 52, Loss: 10.6310\n",
            "Epoch 53, Loss: 10.6260\n",
            "Epoch 54, Loss: 10.6192\n",
            "Epoch 55, Loss: 10.6030\n",
            "Epoch 56, Loss: 10.5912\n",
            "Epoch 57, Loss: 10.5870\n",
            "Epoch 58, Loss: 10.5630\n",
            "Epoch 59, Loss: 10.5436\n",
            "Epoch 60, Loss: 10.5208\n",
            "Epoch 61, Loss: 10.5001\n",
            "Epoch 62, Loss: 10.4857\n",
            "Epoch 63, Loss: 10.4797\n",
            "Epoch 64, Loss: 10.4765\n",
            "Epoch 65, Loss: 10.4705\n",
            "Epoch 66, Loss: 10.4627\n",
            "Epoch 67, Loss: 10.4532\n",
            "Epoch 68, Loss: 10.4470\n",
            "Epoch 69, Loss: 10.4428\n",
            "Epoch 70, Loss: 10.4381\n",
            "Epoch 71, Loss: 10.4342\n",
            "Epoch 72, Loss: 10.4317\n",
            "Epoch 73, Loss: 10.4280\n",
            "Epoch 74, Loss: 10.4246\n",
            "Epoch 75, Loss: 10.4329\n",
            "Epoch 76, Loss: 10.4127\n",
            "Epoch 77, Loss: 10.4071\n",
            "Epoch 78, Loss: 10.3965\n",
            "Epoch 79, Loss: 10.3789\n",
            "Epoch 80, Loss: 10.3500\n",
            "Epoch 81, Loss: 10.3089\n",
            "Epoch 82, Loss: 10.2853\n",
            "Epoch 83, Loss: 10.2297\n",
            "Epoch 84, Loss: 10.2133\n",
            "Epoch 85, Loss: 10.2068\n",
            "Epoch 86, Loss: 10.2016\n",
            "Epoch 87, Loss: 10.1903\n",
            "Epoch 88, Loss: 10.1729\n",
            "Epoch 89, Loss: 10.1486\n",
            "Epoch 90, Loss: 10.1424\n",
            "Epoch 91, Loss: 10.1035\n",
            "Epoch 92, Loss: 10.0784\n",
            "Epoch 93, Loss: 10.0570\n",
            "Epoch 94, Loss: 10.0422\n",
            "Epoch 95, Loss: 10.0318\n",
            "Epoch 96, Loss: 10.0226\n",
            "Epoch 97, Loss: 10.0124\n",
            "Epoch 98, Loss: 9.9981\n",
            "Epoch 99, Loss: 9.9784\n",
            "Epoch 100, Loss: 9.9525\n",
            "Infering sequence 0\n",
            "Infering sequence 1\n",
            "Infering sequence 2\n",
            "Infering sequence 3\n",
            "Infering sequence 4\n",
            "Infering sequence 5\n",
            "Infering sequence 6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Data:\n",
            "{'how are you': 'i am fine <end>',\n",
            " 'how is Adam': 'i dont know <end>',\n",
            " 'tell me about yourself': 'i love travelling, coding<end>',\n",
            " 'what is your name': 'Adam <end>',\n",
            " 'where is Adam': 'at home <end>',\n",
            " 'who are you': 'your companion <end>',\n",
            " 'who is nice': 'Adam <end>'}\n",
            "\n",
            "\n",
            "\n",
            "Model Inference:\n",
            "{'how are you': 'i fine <end>',\n",
            " 'how is Adam': 'i dont know <end>',\n",
            " 'tell me about yourself': 'i love travelling, coding<end> coding<end> '\n",
            "                           'coding<end> coding<end> coding<end> coding<end> '\n",
            "                           'coding<end> coding<end> coding<end>',\n",
            " 'what is your name': 'adam <end>',\n",
            " 'where is Adam': 'at home <end>',\n",
            " 'who are you': '       <end>',\n",
            " 'who is nice': 'adam <end>'}\n"
          ]
        }
      ],
      "source": [
        "training_data, data_words, target_words, vocabulary_words, word_to_ix, ix_to_word = get_data_and_vocab()\n",
        "# Running the example training and inference function\n",
        "example_training_and_inference()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
